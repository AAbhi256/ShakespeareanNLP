{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ShakespeareNLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXnjAnbmvK85"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhmj5BAw2nKe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ae628d9a-4aa3-46fb-b2c6-809a6d44a703"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj9vd6ye2t1n",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "4346be48-951d-4a15-b7e7-5b7a893444e0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f266fe0-c029-4fd6-85ff-347212d7e7e7\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8f266fe0-c029-4fd6-85ff-347212d7e7e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving shakespeare.txt to shakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_X9LQ2f3DMd"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_MJkWJa3GQ5"
      },
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLkGVNtk3M5H"
      },
      "source": [
        "text = open(path_to_file,'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQuR2z_V3Tha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "4866fb26-d1ed-4a25-e965-87c1bec699d5"
      },
      "source": [
        "print(text[140500:141500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reward.\n",
            "  HELENA. Inspired merit so by breath is barr'd.\n",
            "    It is not so with Him that all things knows,\n",
            "    As 'tis with us that square our guess by shows;\n",
            "    But most it is presumption in us when\n",
            "    The help of heaven we count the act of men.\n",
            "    Dear sir, to my endeavours give consent;\n",
            "    Of heaven, not me, make an experiment.\n",
            "    I am not an impostor, that proclaim  \n",
            "    Myself against the level of mine aim;\n",
            "    But know I think, and think I know most sure,\n",
            "    My art is not past power nor you past cure.\n",
            "  KING. Art thou so confident? Within what space\n",
            "    Hop'st thou my cure?\n",
            "  HELENA. The greatest Grace lending grace.\n",
            "    Ere twice the horses of the sun shall bring\n",
            "    Their fiery torcher his diurnal ring,\n",
            "    Ere twice in murk and occidental damp\n",
            "    Moist Hesperus hath quench'd his sleepy lamp,\n",
            "    Or four and twenty times the pilot's glass\n",
            "    Hath told the thievish minutes how they pass,\n",
            "    What is infirm from your sound parts shall fly,\n",
            "    Health shall live free, and s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz1XOAoD3ZUX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "976c4161-eeb7-44da-ccca-bf0a56a4a60f"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '|',\n",
              " '}']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF-sA5Ei3w5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "053a5548-c4f9-4c2e-882d-bb1dd6392f2d"
      },
      "source": [
        "len(vocab) #all unique characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW3qRV973-qb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7288f91c-94c4-4039-a1f1-1c00af11db6b"
      },
      "source": [
        "for pair in enumerate(vocab): #for loop using enumerate for list and printing out the iterating thing creates tuples\n",
        "  print(pair)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '\\n')\n",
            "(1, ' ')\n",
            "(2, '!')\n",
            "(3, '\"')\n",
            "(4, '&')\n",
            "(5, \"'\")\n",
            "(6, '(')\n",
            "(7, ')')\n",
            "(8, ',')\n",
            "(9, '-')\n",
            "(10, '.')\n",
            "(11, '0')\n",
            "(12, '1')\n",
            "(13, '2')\n",
            "(14, '3')\n",
            "(15, '4')\n",
            "(16, '5')\n",
            "(17, '6')\n",
            "(18, '7')\n",
            "(19, '8')\n",
            "(20, '9')\n",
            "(21, ':')\n",
            "(22, ';')\n",
            "(23, '<')\n",
            "(24, '>')\n",
            "(25, '?')\n",
            "(26, 'A')\n",
            "(27, 'B')\n",
            "(28, 'C')\n",
            "(29, 'D')\n",
            "(30, 'E')\n",
            "(31, 'F')\n",
            "(32, 'G')\n",
            "(33, 'H')\n",
            "(34, 'I')\n",
            "(35, 'J')\n",
            "(36, 'K')\n",
            "(37, 'L')\n",
            "(38, 'M')\n",
            "(39, 'N')\n",
            "(40, 'O')\n",
            "(41, 'P')\n",
            "(42, 'Q')\n",
            "(43, 'R')\n",
            "(44, 'S')\n",
            "(45, 'T')\n",
            "(46, 'U')\n",
            "(47, 'V')\n",
            "(48, 'W')\n",
            "(49, 'X')\n",
            "(50, 'Y')\n",
            "(51, 'Z')\n",
            "(52, '[')\n",
            "(53, ']')\n",
            "(54, '_')\n",
            "(55, '`')\n",
            "(56, 'a')\n",
            "(57, 'b')\n",
            "(58, 'c')\n",
            "(59, 'd')\n",
            "(60, 'e')\n",
            "(61, 'f')\n",
            "(62, 'g')\n",
            "(63, 'h')\n",
            "(64, 'i')\n",
            "(65, 'j')\n",
            "(66, 'k')\n",
            "(67, 'l')\n",
            "(68, 'm')\n",
            "(69, 'n')\n",
            "(70, 'o')\n",
            "(71, 'p')\n",
            "(72, 'q')\n",
            "(73, 'r')\n",
            "(74, 's')\n",
            "(75, 't')\n",
            "(76, 'u')\n",
            "(77, 'v')\n",
            "(78, 'w')\n",
            "(79, 'x')\n",
            "(80, 'y')\n",
            "(81, 'z')\n",
            "(82, '|')\n",
            "(83, '}')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzgklAOU41y5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01668655-b713-43e6-d9eb-039a2a788ec7"
      },
      "source": [
        "char_to_ind = {char:ind for ind,char in enumerate(vocab)}\n",
        "char_to_ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7tq1_mo5O33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c35178f7-8965-451f-d2eb-b6922b8fb6db"
      },
      "source": [
        "char_to_ind['H']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWJ7Yg6R5LSW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "5245cce6-6a69-49b1-93ee-c8a6b75f42c3"
      },
      "source": [
        "ind_to_char = np.array(vocab)\n",
        "ind_to_char"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrd8bePW5aaQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "adfd5221-3cff-49bb-8bad-1459e596a3f1"
      },
      "source": [
        "ind_to_char[33]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'H'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbBG8lkf5jTD"
      },
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urcYppXR6OGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2450e12e-5b13-4141-e41e-e79c6faf752b"
      },
      "source": [
        "encoded_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2caMdr8n6UEe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b2cf960-5c81-4666-c809-32d88accbd38"
      },
      "source": [
        "encoded_text.shape #over 5 mil chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5445609,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlZRdOrS6as3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4cd8e4c0-0210-4b5e-8c21-87e105155e5c"
      },
      "source": [
        "sample = text[:500]\n",
        "sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMdppog468H0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "2c05c40d-6e5b-454b-cf1e-cd3efaaf6800"
      },
      "source": [
        "print(sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_191BerZ6hwp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "10ebcc77-2148-4234-af64-0273386b4fb7"
      },
      "source": [
        "encoded_text[:500]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
              "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
              "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
              "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
              "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
              "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
              "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
              "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
              "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
              "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
              "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
              "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
              "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
              "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
              "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
              "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
              "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
              "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
              "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
              "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
              "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
              "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
              "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
              "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
              "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
              "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
              "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
              "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
              "        1, 70, 78, 69,  1, 57, 76])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCj1wk-V6mrq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54cc50c8-934b-4a06-a5b0-8fe1b0770588"
      },
      "source": [
        "line =  \"From fairest creatures we desire increase\"\n",
        "len(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlUxiroL7Dex",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2834bc6d-15b1-446c-fdff-461108b4106c"
      },
      "source": [
        "lines = '''\n",
        "From fairest creatures we desire increase,\n",
        "  That thereby beauty's rose might never die,\n",
        "  But as the riper should by time decease,\n",
        "'''\n",
        "#multiple lines\n",
        "len(lines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAvWDxNG7XaS"
      },
      "source": [
        "seq_len = 120"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yoONfiv7eK6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3c87656a-43e7-404c-fe1f-0a1348f00599"
      },
      "source": [
        "total_num_seq = len(text)/(seq_len+1)\n",
        "total_num_seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005.03305785124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMuwOdPm74h7"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERzPtE5i79TZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b0360d8-26dd-4c63-f115-2eaad10f8c94"
      },
      "source": [
        "type(char_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H8s_btF8lF7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54e43eef-7851-45e4-d405-5526dcba733c"
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO61Laxv7-ys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2877a2f-0601-482e-f80b-7eda7192224d"
      },
      "source": [
        "for item in char_dataset.take(500): #requires eager execution. its why we did weird thing at top with tensorflow importing to get tensorflow 2\n",
        "  print(item.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "12\n",
            "0\n",
            "1\n",
            "1\n",
            "31\n",
            "73\n",
            "70\n",
            "68\n",
            "1\n",
            "61\n",
            "56\n",
            "64\n",
            "73\n",
            "60\n",
            "74\n",
            "75\n",
            "1\n",
            "58\n",
            "73\n",
            "60\n",
            "56\n",
            "75\n",
            "76\n",
            "73\n",
            "60\n",
            "74\n",
            "1\n",
            "78\n",
            "60\n",
            "1\n",
            "59\n",
            "60\n",
            "74\n",
            "64\n",
            "73\n",
            "60\n",
            "1\n",
            "64\n",
            "69\n",
            "58\n",
            "73\n",
            "60\n",
            "56\n",
            "74\n",
            "60\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "45\n",
            "63\n",
            "56\n",
            "75\n",
            "1\n",
            "75\n",
            "63\n",
            "60\n",
            "73\n",
            "60\n",
            "57\n",
            "80\n",
            "1\n",
            "57\n",
            "60\n",
            "56\n",
            "76\n",
            "75\n",
            "80\n",
            "5\n",
            "74\n",
            "1\n",
            "73\n",
            "70\n",
            "74\n",
            "60\n",
            "1\n",
            "68\n",
            "64\n",
            "62\n",
            "63\n",
            "75\n",
            "1\n",
            "69\n",
            "60\n",
            "77\n",
            "60\n",
            "73\n",
            "1\n",
            "59\n",
            "64\n",
            "60\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "27\n",
            "76\n",
            "75\n",
            "1\n",
            "56\n",
            "74\n",
            "1\n",
            "75\n",
            "63\n",
            "60\n",
            "1\n",
            "73\n",
            "64\n",
            "71\n",
            "60\n",
            "73\n",
            "1\n",
            "74\n",
            "63\n",
            "70\n",
            "76\n",
            "67\n",
            "59\n",
            "1\n",
            "57\n",
            "80\n",
            "1\n",
            "75\n",
            "64\n",
            "68\n",
            "60\n",
            "1\n",
            "59\n",
            "60\n",
            "58\n",
            "60\n",
            "56\n",
            "74\n",
            "60\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "33\n",
            "64\n",
            "74\n",
            "1\n",
            "75\n",
            "60\n",
            "69\n",
            "59\n",
            "60\n",
            "73\n",
            "1\n",
            "63\n",
            "60\n",
            "64\n",
            "73\n",
            "1\n",
            "68\n",
            "64\n",
            "62\n",
            "63\n",
            "75\n",
            "1\n",
            "57\n",
            "60\n",
            "56\n",
            "73\n",
            "1\n",
            "63\n",
            "64\n",
            "74\n",
            "1\n",
            "68\n",
            "60\n",
            "68\n",
            "70\n",
            "73\n",
            "80\n",
            "21\n",
            "0\n",
            "1\n",
            "1\n",
            "27\n",
            "76\n",
            "75\n",
            "1\n",
            "75\n",
            "63\n",
            "70\n",
            "76\n",
            "1\n",
            "58\n",
            "70\n",
            "69\n",
            "75\n",
            "73\n",
            "56\n",
            "58\n",
            "75\n",
            "60\n",
            "59\n",
            "1\n",
            "75\n",
            "70\n",
            "1\n",
            "75\n",
            "63\n",
            "64\n",
            "69\n",
            "60\n",
            "1\n",
            "70\n",
            "78\n",
            "69\n",
            "1\n",
            "57\n",
            "73\n",
            "64\n",
            "62\n",
            "63\n",
            "75\n",
            "1\n",
            "60\n",
            "80\n",
            "60\n",
            "74\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "31\n",
            "60\n",
            "60\n",
            "59\n",
            "5\n",
            "74\n",
            "75\n",
            "1\n",
            "75\n",
            "63\n",
            "80\n",
            "1\n",
            "67\n",
            "64\n",
            "62\n",
            "63\n",
            "75\n",
            "5\n",
            "74\n",
            "1\n",
            "61\n",
            "67\n",
            "56\n",
            "68\n",
            "60\n",
            "1\n",
            "78\n",
            "64\n",
            "75\n",
            "63\n",
            "1\n",
            "74\n",
            "60\n",
            "67\n",
            "61\n",
            "9\n",
            "74\n",
            "76\n",
            "57\n",
            "74\n",
            "75\n",
            "56\n",
            "69\n",
            "75\n",
            "64\n",
            "56\n",
            "67\n",
            "1\n",
            "61\n",
            "76\n",
            "60\n",
            "67\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "38\n",
            "56\n",
            "66\n",
            "64\n",
            "69\n",
            "62\n",
            "1\n",
            "56\n",
            "1\n",
            "61\n",
            "56\n",
            "68\n",
            "64\n",
            "69\n",
            "60\n",
            "1\n",
            "78\n",
            "63\n",
            "60\n",
            "73\n",
            "60\n",
            "1\n",
            "56\n",
            "57\n",
            "76\n",
            "69\n",
            "59\n",
            "56\n",
            "69\n",
            "58\n",
            "60\n",
            "1\n",
            "67\n",
            "64\n",
            "60\n",
            "74\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "45\n",
            "63\n",
            "80\n",
            "1\n",
            "74\n",
            "60\n",
            "67\n",
            "61\n",
            "1\n",
            "75\n",
            "63\n",
            "80\n",
            "1\n",
            "61\n",
            "70\n",
            "60\n",
            "8\n",
            "1\n",
            "75\n",
            "70\n",
            "1\n",
            "75\n",
            "63\n",
            "80\n",
            "1\n",
            "74\n",
            "78\n",
            "60\n",
            "60\n",
            "75\n",
            "1\n",
            "74\n",
            "60\n",
            "67\n",
            "61\n",
            "1\n",
            "75\n",
            "70\n",
            "70\n",
            "1\n",
            "58\n",
            "73\n",
            "76\n",
            "60\n",
            "67\n",
            "21\n",
            "0\n",
            "1\n",
            "1\n",
            "45\n",
            "63\n",
            "70\n",
            "76\n",
            "1\n",
            "75\n",
            "63\n",
            "56\n",
            "75\n",
            "1\n",
            "56\n",
            "73\n",
            "75\n",
            "1\n",
            "69\n",
            "70\n",
            "78\n",
            "1\n",
            "75\n",
            "63\n",
            "60\n",
            "1\n",
            "78\n",
            "70\n",
            "73\n",
            "67\n",
            "59\n",
            "5\n",
            "74\n",
            "1\n",
            "61\n",
            "73\n",
            "60\n",
            "74\n",
            "63\n",
            "1\n",
            "70\n",
            "73\n",
            "69\n",
            "56\n",
            "68\n",
            "60\n",
            "69\n",
            "75\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "26\n",
            "69\n",
            "59\n",
            "1\n",
            "70\n",
            "69\n",
            "67\n",
            "80\n",
            "1\n",
            "63\n",
            "60\n",
            "73\n",
            "56\n",
            "67\n",
            "59\n",
            "1\n",
            "75\n",
            "70\n",
            "1\n",
            "75\n",
            "63\n",
            "60\n",
            "1\n",
            "62\n",
            "56\n",
            "76\n",
            "59\n",
            "80\n",
            "1\n",
            "74\n",
            "71\n",
            "73\n",
            "64\n",
            "69\n",
            "62\n",
            "8\n",
            "0\n",
            "1\n",
            "1\n",
            "48\n",
            "64\n",
            "75\n",
            "63\n",
            "64\n",
            "69\n",
            "1\n",
            "75\n",
            "63\n",
            "64\n",
            "69\n",
            "60\n",
            "1\n",
            "70\n",
            "78\n",
            "69\n",
            "1\n",
            "57\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mdagPtl9gTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fa2badb-e5d0-4081-fc2d-9c391d983926"
      },
      "source": [
        "for item in char_dataset.take(500): #requires eager execution. its why we did weird thing at top with tensorflow importing to get tensorflow 2\n",
        "  print(ind_to_char[item.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc-lebUf9r8A"
      },
      "source": [
        "#char_dataset is encoded\n",
        "sequences = char_dataset.batch(seq_len+1,drop_remainder=True) #discards remaining characters. cuz obv our text doesnt perfectly divide perfectly by 120. bye bye remainder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TGaWmWd-JMM"
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "  input_txt = seq[:-1] #['h','e','l','l']\n",
        "  target_txt = seq[1:] #['e','l','l','o']\n",
        "  return input_txt,target_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZMwwvrJ-j9O"
      },
      "source": [
        "dataset = sequences.map(create_seq_targets) #mapping the function to our sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiihWt10-qxN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "a5a26a67-4a33-4cdf-b1cd-87aa588a36cf"
      },
      "source": [
        "for input_txt,target_txt in dataset.take(1):\n",
        "  print(input_txt.numpy())\n",
        "  print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
        "  print('\\n')\n",
        "  print(target_txt.numpy())\n",
        "  print(\"\".join(ind_to_char[target_txt.numpy()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yjdO4-9_GJw"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qdoEA1g_PfU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1a31cc0-6622-4d05-9c77-e2e99094a56a"
      },
      "source": [
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j69Y2mn2_hjo"
      },
      "source": [
        "vocab_size = len(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJyNS45D_qXE"
      },
      "source": [
        "embed_dim = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3uPgsdM_tHx"
      },
      "source": [
        "rnn_neurons = 1026"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR8K5SKuAiFA"
      },
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJD3XJtBAqje",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "9f68b58b-0874-4f8e-d0c4-ffcd2b068462"
      },
      "source": [
        "help(sparse_categorical_crossentropy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Usage:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss.numpy()\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "    \n",
            "    Args:\n",
            "      y_true: Ground truth values.\n",
            "      y_pred: The predicted values.\n",
            "      from_logits: Whether `y_pred` is expected to be a logits tensor. By default,\n",
            "        we assume that `y_pred` encodes a probability distribution.\n",
            "      axis: (Optional) Defaults to -1. The dimension along which the entropy is\n",
            "        computed.\n",
            "    \n",
            "    Returns:\n",
            "      Sparse categorical crossentropy loss value.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GunMoI-TAvJe"
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbw1q-tjBKMF"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOYrHm-KBBP_"
      },
      "source": [
        "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size): \n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
        "  model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
        "  model.add(Dense(vocab_size))\n",
        "  model.compile('adam',loss=sparse_cat_loss) \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sQy2zwmB5-y"
      },
      "source": [
        "model = create_model(vocab_size=vocab_size,\n",
        "                     embed_dim=embed_dim,\n",
        "                     rnn_neurons=rnn_neurons,\n",
        "                     batch_size=batch_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNsWN31yCkGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "2758fc2c-798e-4031-f879-36b145a840fc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 64)           5376      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (128, None, 1026)         3361176   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opPCm9H9C9sb"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  example_batch_predictions = model(input_example_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWATvkqERV1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fda184d1-9e03-4e7b-f5d7-b3979c0b9a2a"
      },
      "source": [
        "example_batch_predictions.shape #number of things(batch size), sequence length, vocab size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([128, 120, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE-f1ouIEVPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "212141d2-f87a-4fa3-dcf7-e1e545d18692"
      },
      "source": [
        "example_batch_predictions[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
              "array([[ 0.00223091, -0.00138323,  0.00283006, ..., -0.00373639,\n",
              "        -0.00701475, -0.00140882],\n",
              "       [-0.00360761,  0.00396621,  0.00481691, ..., -0.00080167,\n",
              "        -0.00711367, -0.00345094],\n",
              "       [ 0.00186118,  0.00136678,  0.00599901, ..., -0.00422146,\n",
              "        -0.00977436, -0.00295338],\n",
              "       ...,\n",
              "       [ 0.00549306, -0.00429622,  0.0004429 , ...,  0.00767957,\n",
              "        -0.00696413,  0.00487974],\n",
              "       [ 0.00662732, -0.00276699,  0.00513185, ...,  0.00454545,\n",
              "        -0.00546218,  0.00558195],\n",
              "       [-0.00841364,  0.00303265,  0.00180447, ...,  0.00021926,\n",
              "        -0.00023777,  0.00206445]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtM786bnEevO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4d176ac-795b-447f-a268-ea3ff8da15b4"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[10],\n",
              "       [23],\n",
              "       [20],\n",
              "       [ 4],\n",
              "       [50],\n",
              "       [ 3],\n",
              "       [10],\n",
              "       [50],\n",
              "       [62],\n",
              "       [ 0],\n",
              "       [66],\n",
              "       [26],\n",
              "       [49],\n",
              "       [63],\n",
              "       [21],\n",
              "       [50],\n",
              "       [80],\n",
              "       [52],\n",
              "       [39],\n",
              "       [51],\n",
              "       [46],\n",
              "       [83],\n",
              "       [17],\n",
              "       [28],\n",
              "       [33],\n",
              "       [18],\n",
              "       [41],\n",
              "       [42],\n",
              "       [21],\n",
              "       [77],\n",
              "       [47],\n",
              "       [70],\n",
              "       [ 1],\n",
              "       [53],\n",
              "       [21],\n",
              "       [43],\n",
              "       [28],\n",
              "       [41],\n",
              "       [20],\n",
              "       [69],\n",
              "       [27],\n",
              "       [36],\n",
              "       [34],\n",
              "       [15],\n",
              "       [65],\n",
              "       [68],\n",
              "       [70],\n",
              "       [33],\n",
              "       [10],\n",
              "       [35],\n",
              "       [66],\n",
              "       [65],\n",
              "       [10],\n",
              "       [ 9],\n",
              "       [16],\n",
              "       [ 0],\n",
              "       [60],\n",
              "       [37],\n",
              "       [56],\n",
              "       [20],\n",
              "       [83],\n",
              "       [ 0],\n",
              "       [74],\n",
              "       [45],\n",
              "       [40],\n",
              "       [13],\n",
              "       [21],\n",
              "       [38],\n",
              "       [27],\n",
              "       [74],\n",
              "       [58],\n",
              "       [31],\n",
              "       [47],\n",
              "       [70],\n",
              "       [57],\n",
              "       [23],\n",
              "       [68],\n",
              "       [48],\n",
              "       [68],\n",
              "       [43],\n",
              "       [43],\n",
              "       [51],\n",
              "       [63],\n",
              "       [24],\n",
              "       [63],\n",
              "       [39],\n",
              "       [76],\n",
              "       [72],\n",
              "       [34],\n",
              "       [66],\n",
              "       [30],\n",
              "       [68],\n",
              "       [37],\n",
              "       [39],\n",
              "       [16],\n",
              "       [ 6],\n",
              "       [74],\n",
              "       [57],\n",
              "       [ 8],\n",
              "       [78],\n",
              "       [28],\n",
              "       [78],\n",
              "       [49],\n",
              "       [24],\n",
              "       [29],\n",
              "       [75],\n",
              "       [ 8],\n",
              "       [ 4],\n",
              "       [13],\n",
              "       [ 0],\n",
              "       [61],\n",
              "       [43],\n",
              "       [37],\n",
              "       [47],\n",
              "       [66],\n",
              "       [39],\n",
              "       [71],\n",
              "       [ 2],\n",
              "       [69],\n",
              "       [56]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbYjH7XEnW6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f77a6e8e-0054-440c-e0e9-632fe68cb4ea"
      },
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "ind_to_char[sampled_indices] #hasnt been trained so obviously the predictions are random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['.', '<', '9', '&', 'Y', '\"', '.', 'Y', 'g', '\\n', 'k', 'A', 'X',\n",
              "       'h', ':', 'Y', 'y', '[', 'N', 'Z', 'U', '}', '6', 'C', 'H', '7',\n",
              "       'P', 'Q', ':', 'v', 'V', 'o', ' ', ']', ':', 'R', 'C', 'P', '9',\n",
              "       'n', 'B', 'K', 'I', '4', 'j', 'm', 'o', 'H', '.', 'J', 'k', 'j',\n",
              "       '.', '-', '5', '\\n', 'e', 'L', 'a', '9', '}', '\\n', 's', 'T', 'O',\n",
              "       '2', ':', 'M', 'B', 's', 'c', 'F', 'V', 'o', 'b', '<', 'm', 'W',\n",
              "       'm', 'R', 'R', 'Z', 'h', '>', 'h', 'N', 'u', 'q', 'I', 'k', 'E',\n",
              "       'm', 'L', 'N', '5', '(', 's', 'b', ',', 'w', 'C', 'w', 'X', '>',\n",
              "       'D', 't', ',', '&', '2', '\\n', 'f', 'R', 'L', 'V', 'k', 'N', 'p',\n",
              "       '!', 'n', 'a'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UKtbhzNE3K0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b8bb182-e4cb-41db-880e-8a4d50689370"
      },
      "source": [
        "epochs=30\n",
        "\n",
        "model.fit(dataset,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "351/351 [==============================] - 49s 140ms/step - loss: 2.5331\n",
            "Epoch 2/30\n",
            "351/351 [==============================] - 51s 146ms/step - loss: 1.7517\n",
            "Epoch 3/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.4722\n",
            "Epoch 4/30\n",
            "351/351 [==============================] - 53s 150ms/step - loss: 1.3476\n",
            "Epoch 5/30\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 1.2824\n",
            "Epoch 6/30\n",
            "351/351 [==============================] - 53s 150ms/step - loss: 1.2417\n",
            "Epoch 7/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.2110\n",
            "Epoch 8/30\n",
            "351/351 [==============================] - 52s 148ms/step - loss: 1.1870\n",
            "Epoch 9/30\n",
            "351/351 [==============================] - 53s 150ms/step - loss: 1.1670\n",
            "Epoch 10/30\n",
            "351/351 [==============================] - 53s 151ms/step - loss: 1.1489\n",
            "Epoch 11/30\n",
            "351/351 [==============================] - 53s 151ms/step - loss: 1.1329\n",
            "Epoch 12/30\n",
            "351/351 [==============================] - 52s 148ms/step - loss: 1.1191\n",
            "Epoch 13/30\n",
            "351/351 [==============================] - 53s 151ms/step - loss: 1.1055\n",
            "Epoch 14/30\n",
            "351/351 [==============================] - 52s 150ms/step - loss: 1.0937\n",
            "Epoch 15/30\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 1.0816\n",
            "Epoch 16/30\n",
            "351/351 [==============================] - 53s 150ms/step - loss: 1.0701\n",
            "Epoch 17/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0597\n",
            "Epoch 18/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0498\n",
            "Epoch 19/30\n",
            "351/351 [==============================] - 51s 147ms/step - loss: 1.0402\n",
            "Epoch 20/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0310\n",
            "Epoch 21/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0232\n",
            "Epoch 22/30\n",
            "351/351 [==============================] - 51s 147ms/step - loss: 1.0151\n",
            "Epoch 23/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0078\n",
            "Epoch 24/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 1.0015\n",
            "Epoch 25/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 0.9964\n",
            "Epoch 26/30\n",
            "351/351 [==============================] - 51s 147ms/step - loss: 0.9902\n",
            "Epoch 27/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 0.9861\n",
            "Epoch 28/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 0.9812\n",
            "Epoch 29/30\n",
            "351/351 [==============================] - 52s 147ms/step - loss: 0.9775\n",
            "Epoch 30/30\n",
            "351/351 [==============================] - 52s 149ms/step - loss: 0.9741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9b45d408d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKvk_zn0LIY4"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYOnD7NQLLJJ"
      },
      "source": [
        "model.save('shakespeare_gen.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl1XvMpuLQfk"
      },
      "source": [
        "model2 = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1) #new untrained model\n",
        "\n",
        "model2.load_weights('shakespeare_gen.h5')\n",
        "\n",
        "model2.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfcZWErJLedE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "e039533e-c242-4e9f-cca1-7aae8dca914f"
      },
      "source": [
        "model2.summary() #yeee"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (1, None, 64)             5376      \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (1, None, 1026)           3361176   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (1, None, 84)             86268     \n",
            "=================================================================\n",
            "Total params: 3,452,820\n",
            "Trainable params: 3,452,820\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5CH0JM5MVHD"
      },
      "source": [
        "def generate_text(model,start_seed,gen_size=500,temp=1.0): #u can specify stuff for gen_size and temp, or leave it at these defaults\n",
        "\n",
        "  num_generate = gen_size\n",
        "\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "  \n",
        "  input_eval = tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = temp \n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "    predictions = model(input_eval) #we can do this cuz of shape of embedding layer\n",
        "\n",
        "    predictions = tf.squeeze(predictions,0)\n",
        "\n",
        "    predictions = predictions/temperature\n",
        "\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\n",
        "\n",
        "    text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return(start_seed+\"\".join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqWbuPG-Nt2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "310ee3f9-1725-45b9-8a5e-83b0fe1236be"
      },
      "source": [
        "print(generate_text(model2,\"JULIET\",gen_size=1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JULIETN. Appress as true, it is not  no leave of my mistress than dead.\n",
            "  GRUMIO. Here is one of the pair;\n",
            "    Now bury me to have chidfledge him true\n",
            "    To have he rotch e.\n",
            "  PROTEUS. O Jupiter!\n",
            "    Holy fiery-tyoul plainly.\n",
            "  ESCALUS. Bid me live again with which lacks more mile, that we may be contedrate\n",
            "    a flesh-him;\n",
            "    And leave you your discreate, tears; for the\n",
            "    strikes are cruel than the poor ocean under whose descended womb\n",
            "    To grant thee wight, did merry angrary.\n",
            "  OBERON. Thou wolf\n",
            "\n",
            "Enter the Duke of Ally-done,\n",
            "                 and others as Cassalo, above\n",
            "\n",
            "  LLOND. Saue it not say, and work therein,\n",
            "    Nor did the rest, and mad'st consent, and a plant it modest even with our king.'\n",
            "    Nay, come away, and be her bed!\n",
            "    It is appraising with the bitter GHOSTS. No princely, give me leave to speak with her\n",
            "    For the flies date proclaim'd the merchant, mangle,\n",
            "    The other for his own will shake us to it.\n",
            "  AGUECHEEK. Mayam, madam, if he may be brought in. We are\n",
            "   \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}